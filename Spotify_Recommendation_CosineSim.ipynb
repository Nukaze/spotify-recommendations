{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install pandas seaborn numpy matplotlib scikit-learn\n","# kagglehub must be python >= 3.9 environment\n","!pip install kagglehub\n","\n","        \n","# !pip install seaborn\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":33,"metadata":{"_cell_guid":"5cba6a11-b920-4c09-b09c-2d229eed5f2f","_uuid":"3bba1de7-d9be-45f6-b7f4-70d613d3873d","collapsed":false,"jupyter":{"outputs_hidden":false},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Path to dataset files: d:\\GitHub\\spotify-recommendations\\data\\tracks_features.csv\n"]}],"source":["import os\n","# Import necessary libraries\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","import kagglehub\n","# Download latest version\n","\n","using_local_dataset = True\n","if (using_local_dataset):\n","    root = os.getcwd()\n","    datasetPath = os.path.join(root, \"data\", \"tracks_features.csv\")\n","else:\n","    datasetPath = kagglehub.dataset_download(\"rodolfofigueroa/spotify-12m-songs\")\n","\n","print(\"Path to dataset files:\", datasetPath)\n","        \n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        datasetPath = os.path.join(dirname, filename)\n","        print(datasetPath)\n","        "]},{"cell_type":"code","execution_count":34,"metadata":{"_cell_guid":"a6c5a3a3-01df-4af7-9532-a97157aeb9e0","_uuid":"9d893666-5916-4c9e-af24-ab76eeb2914f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Error reading dataset: No columns to parse from file\n","Please check the dataset path and try again.\n"]}],"source":["# Load Spotify dataset\n","try:\n","    df = pd.read_csv(datasetPath)\n","    \n","    key_features_all = [\n","        'id', 'name', 'album', 'album_id', \n","        'artists', 'artist_ids', 'track_number', 'disc_number', \n","        'explicit', 'danceability', 'energy', 'key', \n","        'loudness', 'mode', 'speechiness', 'acousticness',\n","        'instrumentalness', 'liveness', 'valence', 'tempo',\n","        'duration_ms', 'time_signature', 'year', 'release_date'\n","    ]\n","\n","    # Exploratory Data Analysis (EDA)\n","    # Display basic statistics\n","    print(df.describe())\n","except Exception as e:\n","    print(\"Error reading dataset:\", e)\n","    print(\"Please check the dataset path and try again.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2fd2456-6122-44fb-8680-f9b828191b8b","_uuid":"56d9f6b8-f2b9-47f9-9914-7f5560814e6c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Filter out non-numeric columns before correlation calculation\n","numeric_df = df.select_dtypes(include=['number'])\n","\n","# Replace infinite values with NaN\n","numeric_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","\n","# Correlation heatmap\n","correlation_matrix = numeric_df.corr()\n","plt.figure(figsize=(12, 10))  # Adjust the figure size as needed\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n","plt.title('Correlation Heatmap')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91bc6a35-c1b1-424e-a770-71737b5321ec","_uuid":"353d4d8d-054f-48b8-ae49-b1dc43ea4926","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#\n","# Distribution of danceability\n","sns.histplot(df['danceability'], bins=20, kde=True)\n","plt.title('Distribution of Danceability')\n","plt.show()\n","\n","# Scatter plot between energy and loudness\n","sns.scatterplot(x='energy', y='loudness', data=df)\n","plt.title('Scatter Plot: Energy vs Loudness')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"571a6da4-d54a-48b0-a4d9-010e8f38032f","_uuid":"833e982a-df90-4edc-9a65-380a1ece5bb8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset\n","file_path = '/kaggle/input/spotify-12m-songs/tracks_features.csv'\n","dft = pd.read_csv(file_path)\n","\n","# Select key features for clustering\n","key_features_interesting = [\n","    'danceability', 'energy', 'key', 'loudness', 'speechiness',\n","    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo'\n","]\n","\n","# Extract the selected features\n","X = dft[key_features_interesting]\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Determine the number of clusters (you may need to choose an appropriate value)\n","num_clusters = 5\n","\n","# Apply k-means clustering\n","kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)  # any value you prefer\n","dft['cluster'] = kmeans.fit_predict(X_scaled)\n","\n","# Visualize the clusters (you may need to adjust for the number of features)\n","for feature in key_features_interesting:\n","    plt.figure(figsize=(12, 6))\n","    for cluster in range(num_clusters):\n","        cluster_data = dft[dft['cluster'] == cluster]\n","        plt.hist(cluster_data[feature], bins=50, alpha=0.5, label=f'Cluster {cluster}')\n","    plt.title(f'Distribution of {str(feature).capitalize()} in Clusters')\n","    plt.xlabel(feature)\n","    plt.ylabel('Frequency')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"7e768396-8285-402d-9745-c716175cce6a","_uuid":"34df4b9d-3cf3-4d0b-9caa-034ea8dcdcb7","trusted":true},"source":["# Main Solution ML Unsupervised Learning\n","# Recommendation system content-based filtering\n","- ## **start running after** this"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f99b2241-5d05-4243-b823-60d3e4a25c1a","_uuid":"dc127098-9c2d-497b-ac62-d63ccad3210a","collapsed":false,"execution":{"iopub.execute_input":"2024-04-13T08:26:51.711869Z","iopub.status.busy":"2024-04-13T08:26:51.711356Z","iopub.status.idle":"2024-04-13T08:26:53.119670Z","shell.execute_reply":"2024-04-13T08:26:53.118106Z","shell.execute_reply.started":"2024-04-13T08:26:51.711830Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Importing necessary libraries\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import linear_kernel\n","import joblib\n","import time\n","\n","# Define file path and sample size\n","file_path = '/kaggle/input/spotify-12m-songs/tracks_features.csv'\n","\n","# Function to sample a subset of the dataset\n","def get_sample_dataset(file_path, sample_size_needed):\n","    return pd.read_csv(file_path).sample(n=sample_size_needed, random_state=42)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Data sampling and Dropping duplicates"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T08:26:53.123581Z","iopub.status.busy":"2024-04-13T08:26:53.122296Z","iopub.status.idle":"2024-04-13T08:27:10.250278Z","shell.execute_reply":"2024-04-13T08:27:10.248801Z","shell.execute_reply.started":"2024-04-13T08:26:53.123526Z"},"trusted":true},"outputs":[],"source":["# performancing process time in unix time standart\n","START_TIME = time.time()\n","\n","sample_size = 50000  # Define the size of the sample\n","\n","# Load a sample of the dataset\n","print(\"get sample dataset\\n\")\n","songs_df = get_sample_dataset(file_path, sample_size)\n","\n","print(\"> drop duplicates\")\n","songs_df.drop_duplicates(inplace=True)\n","print(\"* drop duplicates finish\")"]},{"cell_type":"markdown","metadata":{},"source":["# Handling missing values\n","##### base on all 24 key features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T08:27:10.252921Z","iopub.status.busy":"2024-04-13T08:27:10.252500Z","iopub.status.idle":"2024-04-13T08:27:10.376327Z","shell.execute_reply":"2024-04-13T08:27:10.374794Z","shell.execute_reply.started":"2024-04-13T08:27:10.252886Z"},"trusted":true},"outputs":[],"source":["key_features = [\n","    'id', \"name\", \"album\", \"album_id\", \"artists\", \"artist_ids\",\n","    \"track_number\",'disc_number','explicit','danceability','energy','key',\n","    'loudness','mode','speechiness','acousticness','instrumentalness','liveness',\n","    'valence','tempo','duration_ms','time_signature','year','release_date'\n","]\n","\n","print(\"> drop n/a \")\n","songs_df = songs_df.dropna(subset=key_features)\n","print(\"* drop n/a finish\")"]},{"cell_type":"markdown","metadata":{},"source":["# Feature selection and Combination"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T08:27:10.380042Z","iopub.status.busy":"2024-04-13T08:27:10.379587Z","iopub.status.idle":"2024-04-13T08:27:14.234288Z","shell.execute_reply":"2024-04-13T08:27:14.233233Z","shell.execute_reply.started":"2024-04-13T08:27:10.380006Z"},"trusted":true},"outputs":[],"source":["row_count = songs_df.shape[0]\n","print(f\"After data cleansing, there are still {row_count} records in the dataset.\")\n","\n","# Define desired columns to use for content-based recommendation\n","features = [\n","    'name', 'artists', 'danceability', 'energy', \n","    'loudness', 'tempo', 'duration_ms', 'release_date',\n","    'acousticness', 'speechiness'\n","]\n","\n","# Combine selected features into a single string\n","songs_df['combined_features'] = songs_df[features].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# TF-IDF Vectorization and Cosine Similaraty calculation\n","* ##### performs TF-IDF vectorization on the combined features\n","* ##### computes the cosine similarity matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T08:27:14.236512Z","iopub.status.busy":"2024-04-13T08:27:14.236009Z","iopub.status.idle":"2024-04-13T08:28:11.600697Z","shell.execute_reply":"2024-04-13T08:28:11.599788Z","shell.execute_reply.started":"2024-04-13T08:27:14.236469Z"},"trusted":true},"outputs":[],"source":["\n","# TF-IDF Vectorization\n","print(\"> TF-IDF vectorizing\")\n","tfidf = TfidfVectorizer(stop_words='english')\n","print(\"\\n> TF-IDF fitting\")\n","tfidf_matrix = tfidf.fit_transform(songs_df['combined_features'])\n","print(\"* Finish fitting\\n\")\n","\n","# Compute the cosine similarity matrix\n","print(\"> Cosine_sim computing\")\n","cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n","print(\"* Cosine_sim finish\\n\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Time performance"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T08:28:11.602671Z","iopub.status.busy":"2024-04-13T08:28:11.601931Z","iopub.status.idle":"2024-04-13T08:28:11.608348Z","shell.execute_reply":"2024-04-13T08:28:11.607523Z","shell.execute_reply.started":"2024-04-13T08:28:11.602630Z"},"trusted":true},"outputs":[],"source":["END_TRAIN_TIME = time.time()\n","\n","# calc duration train seconds \n","TRAIN_TIME = round(END_TRAIN_TIME - START_TIME, 4)\n","\n","print(f\"Train {row_count} records\\nWith trianed time = {TRAIN_TIME} seconds\")"]},{"cell_type":"markdown","metadata":{},"source":["# Save trained model to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T08:28:11.610152Z","iopub.status.busy":"2024-04-13T08:28:11.609618Z","iopub.status.idle":"2024-04-13T08:29:37.874095Z","shell.execute_reply":"2024-04-13T08:29:37.870210Z","shell.execute_reply.started":"2024-04-13T08:28:11.610110Z"},"trusted":true},"outputs":[],"source":["\n","# Save the trained model to disk\n","print(\"> dumping tfidf\")\n","joblib.dump(tfidf, 'tfidf_model.pkl')\n","print(\"> dumping cosine_sim\")\n","joblib.dump(cosine_sim, 'cosine_sim_model.pkl')\n","print(\"* dumping cosine_sim finish\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da92c8cb-4baf-45e5-b23c-e789592abbce","_uuid":"4fb99dc0-bb90-4009-83c3-3896d38a380a","collapsed":false,"execution":{"iopub.execute_input":"2024-04-13T08:29:37.878310Z","iopub.status.busy":"2024-04-13T08:29:37.877815Z","iopub.status.idle":"2024-04-13T08:29:37.898100Z","shell.execute_reply":"2024-04-13T08:29:37.896871Z","shell.execute_reply.started":"2024-04-13T08:29:37.878265Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def get_recommendations(song_name, songs_df=songs_df, cosine_sim=cosine_sim, lastTop=5):\n","    # Check if the song name exists in the dataset\n","    if song_name not in songs_df['name'].values:\n","        return \"Song not found in the dataset.\"\n","    \n","    # Get the index of the song that matches the name in the full dataset\n","    full_dataset_idx = songs_df[songs_df['name'] == song_name].index[0]\n","    \n","    # Get the corresponding index in the sampled dataset\n","    sampled_dataset_idx = songs_df.index.get_loc(full_dataset_idx)\n","    \n","    # Get the pairwise similarity scores of all songs with that song\n","    sim_scores = list(enumerate(cosine_sim[sampled_dataset_idx]))\n","    \n","    # Sort the songs based on the similarity scores\n","    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","    \n","    # Get the top N most similar songs\n","    sim_scores = sim_scores[1:1+lastTop]\n","    \n","    # Get the song indices\n","    song_indices = [i[0] for i in sim_scores]\n","    \n","    # Return the top N most similar songs\n","    return songs_df['name'].iloc[song_indices]\n","\n","# Dhong boi\n","def get_recommended_movie(movie_name: str) -> list:\n","    df['distances'] = cosine_similarity (vector, vector [index]) # Here I assume\n","\n","    n = 10 # or however many you want\n","    n_largest = df ['distances'].nlargest (n + 1)\n","\n","    data = []\n","    i = 0\n","\n","    for k, v in n_largest.items():\n","        movie_data = df.loc [df.index == k]\n","\n","        data.append({\n","            'title': (movie_data['title'].values) [0],\n","            'genres': (movie_data['genres'].values) [0],\n","            'overview': (movie_data['overview'].values) [0],\n","            'similarScore': f' {round (v, 2)}%'\n","        })\n","    return data [1::]"]},{"cell_type":"markdown","metadata":{},"source":["# Utilize ML App "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71316db0-5ff9-41f7-9764-600679c0fbb0","_uuid":"8f304019-1387-44cf-be73-e5b5398aa875","collapsed":false,"execution":{"iopub.execute_input":"2024-04-13T08:29:37.900107Z","iopub.status.busy":"2024-04-13T08:29:37.899629Z","iopub.status.idle":"2024-04-13T08:29:38.765278Z","shell.execute_reply":"2024-04-13T08:29:38.764025Z","shell.execute_reply.started":"2024-04-13T08:29:37.900075Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import random\n","# Example usage:\n","print(songs_df['name'])\n","\n","devMode = False\n","\n","if (devMode):\n","    input_song = input(\"\\nEnter your song\\n>\")\n","    if input_song.strip() == \"\":\n","        rnd = random.randrange(0, sample_size-1)\n","        # Default song name if no input provided by random index\n","        input_song = songs_df.iloc[rnd]['name'] \n","else:\n","    rnd = random.randrange(0, sample_size-1)\n","    # Default song name if no input provided by random index\n","    input_song = songs_df.iloc[rnd]['name'] \n","    \n","print(f\"You selected \\\"{input_song}\\\" song\")\n","lastTop = 5\n","\n","START_APP_TIME = time.time()\n","recommendations = get_recommendations(input_song,lastTop=lastTop)\n","END_APP_TIME = time.time()\n","# Seconds duration\n","APP_TIME = round(END_APP_TIME - START_APP_TIME, 6)\n","\n","print(f\"[Top {lastTop}] Recommended songs for \\\"{input_song}\\\": \\n\")\n","print(recommendations)\n","print(f\"processing in {APP_TIME} seconds\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1052176,"sourceId":1770108,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"spotify-rec","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":4}
