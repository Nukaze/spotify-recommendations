{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1770108,"sourceType":"datasetVersion","datasetId":1052176}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        datasetPath = os.path.join(dirname, filename)\n        print(datasetPath)\n        \n        \n# !pip install seaborn\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"3bba1de7-d9be-45f6-b7f4-70d613d3873d","_cell_guid":"5cba6a11-b920-4c09-b09c-2d229eed5f2f","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\n\n# Load Spotify dataset\nfile_path = datasetPath\ndf = pd.read_csv(file_path)\n\nkey_features_all = [\n    'id', 'name', 'album', 'album_id', \n    'artists', 'artist_ids', 'track_number', 'disc_number', \n    'explicit', 'danceability', 'energy', 'key', \n    'loudness', 'mode', 'speechiness', 'acousticness',\n    'instrumentalness', 'liveness', 'valence', 'tempo',\n    'duration_ms', 'time_signature', 'year', 'release_date'\n]\n\n# Exploratory Data Analysis (EDA)\n# Display basic statistics\nprint(df.describe())","metadata":{"_uuid":"9d893666-5916-4c9e-af24-ab76eeb2914f","_cell_guid":"a6c5a3a3-01df-4af7-9532-a97157aeb9e0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \n# Filter out non-numeric columns before correlation calculation\nnumeric_df = df.select_dtypes(include=['number'])\n\n# Replace infinite values with NaN\nnumeric_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n# Correlation heatmap\ncorrelation_matrix = numeric_df.corr()\nplt.figure(figsize=(12, 10))  # Adjust the figure size as needed\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"_uuid":"56d9f6b8-f2b9-47f9-9914-7f5560814e6c","_cell_guid":"f2fd2456-6122-44fb-8680-f9b828191b8b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\n# Distribution of danceability\nsns.histplot(df['danceability'], bins=20, kde=True)\nplt.title('Distribution of Danceability')\nplt.show()\n\n# Scatter plot between energy and loudness\nsns.scatterplot(x='energy', y='loudness', data=df)\nplt.title('Scatter Plot: Energy vs Loudness')\nplt.show()","metadata":{"_uuid":"353d4d8d-054f-48b8-ae49-b1dc43ea4926","_cell_guid":"91bc6a35-c1b1-424e-a770-71737b5321ec","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Load the dataset\nfile_path = '/kaggle/input/spotify-12m-songs/tracks_features.csv'\ndft = pd.read_csv(file_path)\n\n# Select key features for clustering\nkey_features_interesting = [\n    'danceability', 'energy', 'key', 'loudness', 'speechiness',\n    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo'\n]\n\n# Extract the selected features\nX = dft[key_features_interesting]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Determine the number of clusters (you may need to choose an appropriate value)\nnum_clusters = 5\n\n# Apply k-means clustering\nkmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)  # any value you prefer\ndft['cluster'] = kmeans.fit_predict(X_scaled)\n\n# Visualize the clusters (you may need to adjust for the number of features)\nfor feature in key_features_interesting:\n    plt.figure(figsize=(12, 6))\n    for cluster in range(num_clusters):\n        cluster_data = dft[dft['cluster'] == cluster]\n        plt.hist(cluster_data[feature], bins=50, alpha=0.5, label=f'Cluster {cluster}')\n    plt.title(f'Distribution of {str(feature).capitalize()} in Clusters')\n    plt.xlabel(feature)\n    plt.ylabel('Frequency')\n    plt.legend()\n    plt.show()","metadata":{"_uuid":"833e982a-df90-4edc-9a65-380a1ece5bb8","_cell_guid":"571a6da4-d54a-48b0-a4d9-010e8f38032f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Solution ML Unsupervised Learning\n# Recommendation system content-based filtering\n- ## **start running after** this","metadata":{"_uuid":"34df4b9d-3cf3-4d0b-9caa-034ea8dcdcb7","_cell_guid":"7e768396-8285-402d-9745-c716175cce6a","trusted":true}},{"cell_type":"code","source":"# Importing necessary libraries\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nimport joblib\nimport time\n\n# Define file path and sample size\nfile_path = '/kaggle/input/spotify-12m-songs/tracks_features.csv'\n\n# Function to sample a subset of the dataset\ndef get_sample_dataset(file_path, sample_size_needed):\n    return pd.read_csv(file_path).sample(n=sample_size_needed, random_state=42)\n","metadata":{"_uuid":"dc127098-9c2d-497b-ac62-d63ccad3210a","_cell_guid":"f99b2241-5d05-4243-b823-60d3e4a25c1a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T08:26:51.711356Z","iopub.execute_input":"2024-04-13T08:26:51.711869Z","iopub.status.idle":"2024-04-13T08:26:53.119670Z","shell.execute_reply.started":"2024-04-13T08:26:51.711830Z","shell.execute_reply":"2024-04-13T08:26:53.118106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data sampling and Dropping duplicates","metadata":{}},{"cell_type":"code","source":"# performancing process time in unix time standart\nSTART_TIME = time.time()\n\nsample_size = 50000  # Define the size of the sample\n\n# Load a sample of the dataset\nprint(\"get sample dataset\\n\")\nsongs_df = get_sample_dataset(file_path, sample_size)\n\nprint(\"> drop duplicates\")\nsongs_df.drop_duplicates(inplace=True)\nprint(\"* drop duplicates finish\")","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:26:53.122296Z","iopub.execute_input":"2024-04-13T08:26:53.123581Z","iopub.status.idle":"2024-04-13T08:27:10.250278Z","shell.execute_reply.started":"2024-04-13T08:26:53.123526Z","shell.execute_reply":"2024-04-13T08:27:10.248801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling missing values\n##### base on all 24 key features","metadata":{}},{"cell_type":"code","source":"key_features = [\n    'id', \"name\", \"album\", \"album_id\", \"artists\", \"artist_ids\",\n    \"track_number\",'disc_number','explicit','danceability','energy','key',\n    'loudness','mode','speechiness','acousticness','instrumentalness','liveness',\n    'valence','tempo','duration_ms','time_signature','year','release_date'\n]\n\nprint(\"> drop n/a \")\nsongs_df = songs_df.dropna(subset=key_features)\nprint(\"* drop n/a finish\")","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:27:10.252500Z","iopub.execute_input":"2024-04-13T08:27:10.252921Z","iopub.status.idle":"2024-04-13T08:27:10.376327Z","shell.execute_reply.started":"2024-04-13T08:27:10.252886Z","shell.execute_reply":"2024-04-13T08:27:10.374794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature selection and Combination","metadata":{}},{"cell_type":"code","source":"row_count = songs_df.shape[0]\nprint(f\"After data cleansing, there are still {row_count} records in the dataset.\")\n\n# Define desired columns to use for content-based recommendation\nfeatures = [\n    'name', 'artists', 'danceability', 'energy', \n    'loudness', 'tempo', 'duration_ms', 'release_date',\n    'acousticness', 'speechiness'\n]\n\n# Combine selected features into a single string\nsongs_df['combined_features'] = songs_df[features].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:27:10.379587Z","iopub.execute_input":"2024-04-13T08:27:10.380042Z","iopub.status.idle":"2024-04-13T08:27:14.234288Z","shell.execute_reply.started":"2024-04-13T08:27:10.380006Z","shell.execute_reply":"2024-04-13T08:27:14.233233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TF-IDF Vectorization and Cosine Similaraty calculation\n* ##### performs TF-IDF vectorization on the combined features\n* ##### computes the cosine similarity matrix.","metadata":{}},{"cell_type":"code","source":"\n# TF-IDF Vectorization\nprint(\"> TF-IDF vectorizing\")\ntfidf = TfidfVectorizer(stop_words='english')\nprint(\"\\n> TF-IDF fitting\")\ntfidf_matrix = tfidf.fit_transform(songs_df['combined_features'])\nprint(\"* Finish fitting\\n\")\n\n# Compute the cosine similarity matrix\nprint(\"> Cosine_sim computing\")\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\nprint(\"* Cosine_sim finish\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:27:14.236009Z","iopub.execute_input":"2024-04-13T08:27:14.236512Z","iopub.status.idle":"2024-04-13T08:28:11.600697Z","shell.execute_reply.started":"2024-04-13T08:27:14.236469Z","shell.execute_reply":"2024-04-13T08:28:11.599788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Time performance","metadata":{}},{"cell_type":"code","source":"END_TRAIN_TIME = time.time()\n\n# calc duration train seconds \nTRAIN_TIME = round(END_TRAIN_TIME - START_TIME, 4)\n\nprint(f\"Train {row_count} records\\nWith trianed time = {TRAIN_TIME} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:28:11.601931Z","iopub.execute_input":"2024-04-13T08:28:11.602671Z","iopub.status.idle":"2024-04-13T08:28:11.608348Z","shell.execute_reply.started":"2024-04-13T08:28:11.602630Z","shell.execute_reply":"2024-04-13T08:28:11.607523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save trained model to disk","metadata":{}},{"cell_type":"code","source":"\n# Save the trained model to disk\nprint(\"> dumping tfidf\")\njoblib.dump(tfidf, 'tfidf_model.pkl')\nprint(\"> dumping cosine_sim\")\njoblib.dump(cosine_sim, 'cosine_sim_model.pkl')\nprint(\"* dumping cosine_sim finish\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:28:11.609618Z","iopub.execute_input":"2024-04-13T08:28:11.610152Z","iopub.status.idle":"2024-04-13T08:29:37.874095Z","shell.execute_reply.started":"2024-04-13T08:28:11.610110Z","shell.execute_reply":"2024-04-13T08:29:37.870210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_recommendations(song_name, songs_df=songs_df, cosine_sim=cosine_sim, lastTop=5):\n    # Check if the song name exists in the dataset\n    if song_name not in songs_df['name'].values:\n        return \"Song not found in the dataset.\"\n    \n    # Get the index of the song that matches the name in the full dataset\n    full_dataset_idx = songs_df[songs_df['name'] == song_name].index[0]\n    \n    # Get the corresponding index in the sampled dataset\n    sampled_dataset_idx = songs_df.index.get_loc(full_dataset_idx)\n    \n    # Get the pairwise similarity scores of all songs with that song\n    sim_scores = list(enumerate(cosine_sim[sampled_dataset_idx]))\n    \n    # Sort the songs based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    \n    # Get the top N most similar songs\n    sim_scores = sim_scores[1:1+lastTop]\n    \n    # Get the song indices\n    song_indices = [i[0] for i in sim_scores]\n    \n    # Return the top N most similar songs\n    return songs_df['name'].iloc[song_indices]\n\n# Dhong boi\ndef get_recommended_movie(movie_name: str) -> list:\n    df['distances'] = cosine_similarity (vector, vector [index]) # Here I assume\n\n    n = 10 # or however many you want\n    n_largest = df ['distances'].nlargest (n + 1)\n\n    data = []\n    i = 0\n\n    for k, v in n_largest.items():\n        movie_data = df.loc [df.index == k]\n\n        data.append({\n            'title': (movie_data['title'].values) [0],\n            'genres': (movie_data['genres'].values) [0],\n            'overview': (movie_data['overview'].values) [0],\n            'similarScore': f' {round (v, 2)}%'\n        })\n    return data [1::]","metadata":{"_uuid":"4fb99dc0-bb90-4009-83c3-3896d38a380a","_cell_guid":"da92c8cb-4baf-45e5-b23c-e789592abbce","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T08:29:37.877815Z","iopub.execute_input":"2024-04-13T08:29:37.878310Z","iopub.status.idle":"2024-04-13T08:29:37.898100Z","shell.execute_reply.started":"2024-04-13T08:29:37.878265Z","shell.execute_reply":"2024-04-13T08:29:37.896871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utilize ML App ","metadata":{}},{"cell_type":"code","source":"import random\n# Example usage:\nprint(songs_df['name'])\n\ndevMode = False\n\nif (devMode):\n    input_song = input(\"\\nEnter your song\\n>\")\n    if input_song.strip() == \"\":\n        rnd = random.randrange(0, sample_size-1)\n        # Default song name if no input provided by random index\n        input_song = songs_df.iloc[rnd]['name'] \nelse:\n    rnd = random.randrange(0, sample_size-1)\n    # Default song name if no input provided by random index\n    input_song = songs_df.iloc[rnd]['name'] \n    \nprint(f\"You selected \\\"{input_song}\\\" song\")\nlastTop = 5\n\nSTART_APP_TIME = time.time()\nrecommendations = get_recommendations(input_song,lastTop=lastTop)\nEND_APP_TIME = time.time()\n# Seconds duration\nAPP_TIME = round(END_APP_TIME - START_APP_TIME, 6)\n\nprint(f\"[Top {lastTop}] Recommended songs for \\\"{input_song}\\\": \\n\")\nprint(recommendations)\nprint(f\"processing in {APP_TIME} seconds\")","metadata":{"_uuid":"8f304019-1387-44cf-be73-e5b5398aa875","_cell_guid":"71316db0-5ff9-41f7-9764-600679c0fbb0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T08:29:37.899629Z","iopub.execute_input":"2024-04-13T08:29:37.900107Z","iopub.status.idle":"2024-04-13T08:29:38.765278Z","shell.execute_reply.started":"2024-04-13T08:29:37.900075Z","shell.execute_reply":"2024-04-13T08:29:38.764025Z"},"trusted":true},"execution_count":null,"outputs":[]}]}